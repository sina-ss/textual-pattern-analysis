{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Pattern Analysis with Unigram and Bigram Models\n",
    "\n",
    "In this project we perform a basic language processing task on a given piece of text, focusing on identifying and analyzing unigrams and bigrams within the text. Furthermore, it also assesses the likelihood of occurrence for a randomly generated string of words based on the computed bigram model.\n",
    "\n",
    "The text selected for this project is:\n",
    "\n",
    "`One use of sentence embeddings is information retrieval. Consider the task of searching the Snap! manual or this AI programming guide. String matching cannot take into account synonyms, different ways of saying the same thing, or different spelling conventions. In this sample search project sentence embeddings are used to compare the user's query with sentence fragments from the manual and guide. By relying on the features closest to the list of features block the closest fragments are found very quickly. The embeddings of all the fragments have been pre-computed so only the embedding of the user's query is needed.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "First, we will preprocess the text. We will tokenize the text, which means that we will split it into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Our input paragraph\n",
    "input_paragraph = \"One use of sentence embeddings is information retrieval. Consider the task of searching the Snap! manual or this AI programming guide. String matching cannot take into account synonyms, different ways of saying the same thing, or different spelling conventions. In this sample search project sentence embeddings are used to compare the user's query with sentence fragments from the manual and guide. By relying on the features closest to the list of features block the closest fragments are found very quickly. The embeddings of all the fragments have been pre-computed so only the embedding of the user's query is needed.\"\n",
    "\n",
    "# Tokenize the paragraph into words\n",
    "tokens = word_tokenize(input_paragraph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram and Bigram Calculation\n",
    "Next, we calculate the unigrams and bigrams. Unigrams are just the individual words in the text, and bigrams are pairs of words that occur in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# Calculate unigrams\n",
    "unigrams = list(ngrams(tokens, 1))\n",
    "\n",
    "# Calculate bigrams\n",
    "bigrams = list(ngrams(tokens, 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display this in a table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             word\n",
      "0             One\n",
      "1             use\n",
      "2              of\n",
      "3        sentence\n",
      "4      embeddings\n",
      "5              is\n",
      "6     information\n",
      "7       retrieval\n",
      "8               .\n",
      "9        Consider\n",
      "10            the\n",
      "11           task\n",
      "12             of\n",
      "13      searching\n",
      "14            the\n",
      "15           Snap\n",
      "16              !\n",
      "17         manual\n",
      "18             or\n",
      "19           this\n",
      "20             AI\n",
      "21    programming\n",
      "22          guide\n",
      "23              .\n",
      "24         String\n",
      "25       matching\n",
      "26            can\n",
      "27            not\n",
      "28           take\n",
      "29           into\n",
      "30        account\n",
      "31       synonyms\n",
      "32              ,\n",
      "33      different\n",
      "34           ways\n",
      "35             of\n",
      "36         saying\n",
      "37            the\n",
      "38           same\n",
      "39          thing\n",
      "40              ,\n",
      "41             or\n",
      "42      different\n",
      "43       spelling\n",
      "44    conventions\n",
      "45              .\n",
      "46             In\n",
      "47           this\n",
      "48         sample\n",
      "49         search\n",
      "50        project\n",
      "51       sentence\n",
      "52     embeddings\n",
      "53            are\n",
      "54           used\n",
      "55             to\n",
      "56        compare\n",
      "57            the\n",
      "58           user\n",
      "59             's\n",
      "60          query\n",
      "61           with\n",
      "62       sentence\n",
      "63      fragments\n",
      "64           from\n",
      "65            the\n",
      "66         manual\n",
      "67            and\n",
      "68          guide\n",
      "69              .\n",
      "70             By\n",
      "71        relying\n",
      "72             on\n",
      "73            the\n",
      "74       features\n",
      "75        closest\n",
      "76             to\n",
      "77            the\n",
      "78           list\n",
      "79             of\n",
      "80       features\n",
      "81          block\n",
      "82            the\n",
      "83        closest\n",
      "84      fragments\n",
      "85            are\n",
      "86          found\n",
      "87           very\n",
      "88        quickly\n",
      "89              .\n",
      "90            The\n",
      "91     embeddings\n",
      "92             of\n",
      "93            all\n",
      "94            the\n",
      "95      fragments\n",
      "96           have\n",
      "97           been\n",
      "98   pre-computed\n",
      "99             so\n",
      "100          only\n",
      "101           the\n",
      "102     embedding\n",
      "103            of\n",
      "104           the\n",
      "105          user\n",
      "106            's\n",
      "107         query\n",
      "108            is\n",
      "109        needed\n",
      "110             .\n",
      "            word1         word2\n",
      "0             One           use\n",
      "1             use            of\n",
      "2              of      sentence\n",
      "3        sentence    embeddings\n",
      "4      embeddings            is\n",
      "5              is   information\n",
      "6     information     retrieval\n",
      "7       retrieval             .\n",
      "8               .      Consider\n",
      "9        Consider           the\n",
      "10            the          task\n",
      "11           task            of\n",
      "12             of     searching\n",
      "13      searching           the\n",
      "14            the          Snap\n",
      "15           Snap             !\n",
      "16              !        manual\n",
      "17         manual            or\n",
      "18             or          this\n",
      "19           this            AI\n",
      "20             AI   programming\n",
      "21    programming         guide\n",
      "22          guide             .\n",
      "23              .        String\n",
      "24         String      matching\n",
      "25       matching           can\n",
      "26            can           not\n",
      "27            not          take\n",
      "28           take          into\n",
      "29           into       account\n",
      "30        account      synonyms\n",
      "31       synonyms             ,\n",
      "32              ,     different\n",
      "33      different          ways\n",
      "34           ways            of\n",
      "35             of        saying\n",
      "36         saying           the\n",
      "37            the          same\n",
      "38           same         thing\n",
      "39          thing             ,\n",
      "40              ,            or\n",
      "41             or     different\n",
      "42      different      spelling\n",
      "43       spelling   conventions\n",
      "44    conventions             .\n",
      "45              .            In\n",
      "46             In          this\n",
      "47           this        sample\n",
      "48         sample        search\n",
      "49         search       project\n",
      "50        project      sentence\n",
      "51       sentence    embeddings\n",
      "52     embeddings           are\n",
      "53            are          used\n",
      "54           used            to\n",
      "55             to       compare\n",
      "56        compare           the\n",
      "57            the          user\n",
      "58           user            's\n",
      "59             's         query\n",
      "60          query          with\n",
      "61           with      sentence\n",
      "62       sentence     fragments\n",
      "63      fragments          from\n",
      "64           from           the\n",
      "65            the        manual\n",
      "66         manual           and\n",
      "67            and         guide\n",
      "68          guide             .\n",
      "69              .            By\n",
      "70             By       relying\n",
      "71        relying            on\n",
      "72             on           the\n",
      "73            the      features\n",
      "74       features       closest\n",
      "75        closest            to\n",
      "76             to           the\n",
      "77            the          list\n",
      "78           list            of\n",
      "79             of      features\n",
      "80       features         block\n",
      "81          block           the\n",
      "82            the       closest\n",
      "83        closest     fragments\n",
      "84      fragments           are\n",
      "85            are         found\n",
      "86          found          very\n",
      "87           very       quickly\n",
      "88        quickly             .\n",
      "89              .           The\n",
      "90            The    embeddings\n",
      "91     embeddings            of\n",
      "92             of           all\n",
      "93            all           the\n",
      "94            the     fragments\n",
      "95      fragments          have\n",
      "96           have          been\n",
      "97           been  pre-computed\n",
      "98   pre-computed            so\n",
      "99             so          only\n",
      "100          only           the\n",
      "101           the     embedding\n",
      "102     embedding            of\n",
      "103            of           the\n",
      "104           the          user\n",
      "105          user            's\n",
      "106            's         query\n",
      "107         query            is\n",
      "108            is        needed\n",
      "109        needed             .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert unigrams and bigrams to dataframes\n",
    "unigram_df = pd.DataFrame(unigrams, columns=['word'])\n",
    "bigram_df = pd.DataFrame(bigrams, columns=['word1', 'word2'])\n",
    "\n",
    "# Displays unigram and bigram dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(unigram_df)\n",
    "print(bigram_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random String Generation and Probability Calculation\n",
    "Now we will generate a random string of words with a length less than 5. Then we'll calculate the probability of this string occurring in our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random string: ['fragments', 'are']\n",
      "Probability: 0.009523809523809525\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_string_prob = 0\n",
    "while (random_string_prob == 0 or random_string_prob == 1):\n",
    "    # Generate a random string of words with length less than 5\n",
    "    random_string_length = random.randint(1, 4)\n",
    "    random_string = random.sample(tokens, random_string_length)\n",
    "    # Calculate the probability of the random string\n",
    "    bigram_freq = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "    random_string_bigrams = list(ngrams(random_string, 2))\n",
    "    random_string_prob = 1\n",
    "    for bigram in random_string_bigrams:\n",
    "        random_string_prob *= (bigram_freq[bigram] / len(bigram_freq))\n",
    "\n",
    "print(\"Random string:\", random_string)\n",
    "print(\"Probability:\", random_string_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "**You can find the full details in `report.pdf`**\n",
    "\n",
    "This project uses basic Natural Language Processing (NLP) techniques to analyze a piece of text. The nltk library in Python is a powerful tool for such text analysis tasks. The project could be extended by performing more complex analysis on the text, such as calculating trigrams or applying machine learning techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
